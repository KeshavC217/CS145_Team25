{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.integrate import odeint\n",
    "import math\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "#import csvs\n",
    "train = pd.read_csv(\"../../data/train.csv\")\n",
    "test = pd.read_csv(\"../../data/test.csv\")\n",
    "graph = pd.read_csv(\"../../data/graph.csv\")\n",
    "\n",
    "statesdata = {}\n",
    "states = pd.Series.unique(train['Province_State'])\n",
    "num_states = len(states)\n",
    "for s in states:\n",
    "    statesdata[s] = train.loc[train['Province_State'] == s ,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p,d,q = 5,2,3\n",
    "days = 26\n",
    "\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "\n",
    "def predictARIMA(X, p, d, q, days):\n",
    "    model = ARIMA(X, order=(p,d,q))\n",
    "    model_fit = model.fit()\n",
    "    start = len(X)\n",
    "    forecast = model_fit.predict(start = start, end = start + days)\n",
    "    return(forecast)\n",
    "\n",
    "\n",
    "proj = {}\n",
    "for s in states:\n",
    "    a = statesdata[s]\n",
    "    a = a.reset_index()\n",
    "    confirmed = a['Confirmed']\n",
    "    deaths = a['Deaths']\n",
    "    \n",
    "    X = confirmed.values\n",
    "    \n",
    "    forecastC = predictARIMA(X, 10,2,1, days)\n",
    "    # BEST PARAMS SO FAR ARE 2,2,1\n",
    "    \n",
    "    Y= deaths.values\n",
    "\n",
    "    forecastD = predictARIMA(Y, 4,2,3, days)\n",
    "    # BEST PARAMS SO FAR ARE 4,2,3\n",
    "\n",
    "    df = {'Confirmed': forecastC, 'Deaths': forecastD}\n",
    "    \n",
    "    proj[s] = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = test.loc[0:49,'Province_State']\n",
    "\n",
    "# format submission\n",
    "conf = []\n",
    "dead = []\n",
    "fid = 0\n",
    "for i in range(days):\n",
    "    for j in order:\n",
    "        projection = proj[j].iloc[i]\n",
    "        #print(j, 'day', i)\n",
    "        conf.append(int(projection['Confirmed']))\n",
    "        dead.append(int(projection['Deaths']))\n",
    "        #print(fid)\n",
    "        fid+=1\n",
    "\n",
    "test['Confirmed'] = conf\n",
    "test['Deaths'] = dead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test.drop(columns=['Province_State', 'Date'])\n",
    "#print(submission)\n",
    "submission.to_csv('team25.csv', index = False, header = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# USAGE: team25.csv is the csv we want to test (our predictions), ground truth doesn't change\n",
    "def give_mape(ground_truth_path, prediction_path):\n",
    "    ground_truth = pd.read_csv(ground_truth_path)\n",
    "    predictions = pd.read_csv(prediction_path)\n",
    "\n",
    "    gt_conf = ground_truth['Confirmed']\n",
    "    gt_dead = ground_truth['Deaths']\n",
    "\n",
    "    pred_conf = predictions['Confirmed']\n",
    "    pred_dead = predictions['Deaths']\n",
    "\n",
    "    total = 0\n",
    "    for i in range(1300):\n",
    "        conf_error = float(pred_conf[i] - gt_conf[i]) / float(gt_conf[i])\n",
    "        dead_error = float(pred_dead[i] - gt_dead[i]) / float(gt_dead[i])\n",
    "        total = total + abs(conf_error) + abs(dead_error)\n",
    "\n",
    "    total = total / 2600\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02445393704323451\n"
     ]
    }
   ],
   "source": [
    "print(give_mape('team25.csv', '../ValidationTester/ground_truth.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}